\section{Correctness Proofs}

This section argues for the correctness of the Byzantine Generalized Paxos protocol in terms of the specified consensus properties.\par


\begin{table}[h!]
	\renewcommand{\arraystretch}{1.5}
	\centering
	\begin{tabularx}{\linewidth}{ |c|X|}
		%\hline
		%\multicolumn{2}{|c|}{Notation}\\
		\hline
		Invariant/Symbol & Definition \\
		\hline
		$\thicksim$ & Equivalence relation between sequences \\
		\hline
		$X \overset{e}{\implies} Y$ & $X$ implies that $Y$ is eventually true \\
		\hline
		$X \sqsubseteq Y$ & The sequence $X$ is a prefix of sequence $Y$ \\
		\hline
		$\mathcal{L}$ & Set of learner processes \\
		\hline
		$\mathcal{P}$ & Set of proposals (commands or sequences of commands) \\
		\hline
		$learned_{l_i}$ & Learner $l_i$'s $learned$ sequence of commands \\
		\hline
		$learned(l_i,s)$ & $learned_{l_i}$ contains the sequence $s$ \\
		\hline
		$maj\_accepted(s)$ & $N-f$ acceptors sent phase 2b messages to the learners for sequence $s$ \\
		\hline
		$min\_accepted(s)$ & $f+1$ acceptors sent phase 2b messages to the learners for sequence $s$ \\
		\hline
		$proposed(s)$ & A proposer proposed $s$ \\
		\hline
		
	\end{tabularx} 
	\caption{Proof notation} 
	\label{table:1}
\end{table}

\subsubsection{Consistency}
\begin{theorem}At any time and for any two correct learners $l_i$ and $l_j$, $learned_{l_i}$ and $learned_{l_j}$ can subsequently be extended to equivalent sequences \par
\end{theorem} 
\textbf{Proof:} \par
\parbox{\linewidth}{\strut1. At any given instant, $\forall s,s' \in \mathcal{P}, \forall l_i,l_j \in \mathcal{L}, learned(l_j,s) \land learned(l_i,s') \implies \exists \sigma_1,\sigma_2 \in \mathcal{P}, s \thicksim s' \bullet \sigma_1 \lor s' \thicksim s \bullet \sigma_2$}  \par
\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} }\par
\indent\indent\indent\parbox{\linewidth-\algorithmicindent*3}{\strut1.1. At any given instant, $\forall s,s' \in \mathcal{P}, \forall l_i,l_j \in \mathcal{L}, learned(l_i,s) \land learned(l_j,s') \implies (maj\_accepted(s) \lor (min\_accepted(s) \land (s \thicksim x \bullet \sigma_1 \lor x \thicksim s \bullet \sigma_2))) \land (maj\_accepted(s') \lor (min\_accepted(s') \land (s' \thicksim x \bullet \sigma_1 \lor x \thicksim s' \bullet \sigma_2))), \exists \sigma_1, \sigma_2 \in \mathcal{P}, \forall x \in \mathcal{P}$} \par
\indent\indent\indent\indent\parbox{\linewidth-\algorithmicindent*4}{\strut\textbf{Proof:} By Algorithm \ref{BFT-Learn} lines \{1-4\}, a sequence can only be learned if the learner gathers $N-f$ votes (i.e., $maj\_accepted(s)$) or if it is universally commutative (i.e., $s \thicksim x \bullet \sigma_1 \lor x \thicksim s \bullet \sigma_2,\ \exists \sigma_1, \sigma_2 \in \mathcal{P}, \forall x \in \mathcal{P}$) and the learner gathers $f+1$ votes (i.e., $min\_accepted(s)$). The logical expression $s \thicksim x \bullet \sigma_1 \lor x \thicksim \bullet \sigma_2$ is true when either the learned sequence $s$ can be extended with a suffix $\sigma_1$ to any other sequence $x$ or if any sequence $x$ can be extended with some prefix $\sigma_2$ to be equivalent to $s$.}
\indent\indent\indent\parbox{\linewidth-\algorithmicindent*3}{\strut1.2. At any given instant, $\forall s,s' \in \mathcal{P}, maj\_accepted(s) \land maj\_accepted(s') \implies \exists \sigma_1,\sigma_2 \in \mathcal{P}, s \thicksim s' \bullet \sigma_1 \lor s' \thicksim s \bullet \sigma_2$}\par
\indent\indent\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} Proved by contradiction.}\par
\indent\indent\indent\indent\indent\parbox{\linewidth-\algorithmicindent*5}{\strut1.2.1.~At any given instant, $\exists s,s' \in \mathcal{P}, \forall \sigma_1,\sigma_2 \in \mathcal{P}, maj\_accepted(s) \land maj\_accepted(s') \wedge s \not\thicksim s' \bullet \sigma_1 \land s' \not\thicksim s \bullet \sigma_2$} \par
\indent\indent\indent\indent\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} Contradiction assumption.}\par
\indent\indent\indent\indent\indent\parbox{\linewidth-\algorithmicindent*5}{\strut1.2.2. Take $s$ and $s'$ which are certain to exist by 1.2.1, $s$ and $s'$ are non-commutative }\par
\indent\indent\indent\indent\indent\indent\parbox{\linewidth-\algorithmicindent*6}{\strut\textbf{Proof:} If $\forall \sigma_1,\sigma_2 \in \mathcal{P}, s \not\thicksim s' \bullet \sigma_1 \land s' \not\thicksim s \bullet \sigma_2$ then $s$ and $s'$ must contain non-commutative commands differently ordered. Otherwise, they would be possible to extend to equivalent sequences.}\par
\indent\indent\indent\indent\indent\parbox{\linewidth}{\strut1.2.3. At any given instant, $\neg (maj\_accepted(s) \land maj\_accepted(s'))$ } \par
\indent\indent\indent\indent\indent\indent\parbox{\linewidth-\algorithmicindent*6}{\strut\textbf{Proof:} Since $s$ and $s'$ are non-commutative, therefore not equivalent, and each correct acceptor only votes once for a new proposal (Algorithm \ref{BFT-Acc}, lines \{28-43\}), any learner will only obtain $N-f$ votes for one of the sequences (Algorithm \ref{BFT-Learn}, lines \{1-4\}).}\par
\indent\indent\indent\indent\indent\parbox{\linewidth}{\strut1.2.4. Q.E.D. }\par
\indent\indent\indent\parbox{\linewidth-\algorithmicindent*3}{\strut1.3. Take $s$ and $s'$, at any given instant, $\forall x \in \mathcal{P}, \exists \sigma_1,\sigma_2 \in \mathcal{P}, (maj\_accepted(s) \lor (min\_accepted(s) \land (s \thicksim x \bullet \sigma_1 \lor x \thicksim s \bullet \sigma_2))) \land (maj\_accepted(s') \lor (min\_accepted(s') \land (s' \thicksim x \bullet \sigma_1 \lor x \thicksim s' \bullet \sigma_2))) \implies s \thicksim x \bullet \sigma$}\par
\indent\indent\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} By 1.2 and by definition of $(s \thicksim x \bullet \sigma \lor x \thicksim s \bullet \sigma)$.}\par
\indent\indent\indent\parbox{\linewidth-\algorithmicindent*3}{\strut1.4. At any given instant, $\forall s,s' \in \mathcal{P}, \forall l_i,l_j \in \mathcal{L}, learned(l_i,s)\ \land\ learned(l_j,s') \implies \exists \sigma_1,\sigma_2 \in \mathcal{P}, s \thicksim s' \bullet \sigma_1 \lor s' \thicksim s \bullet \sigma_2$ }\par
\indent\indent\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} By 1.1 and 1.3.}\par
\indent\indent\indent\parbox{\linewidth}{\strut1.5. Q.E.D. }\par
\parbox{\linewidth-\algorithmicindent*3}{\strut2. At any given instant, $\forall l_i,l_j \in \mathcal{L}, learned(l_j,learned_j) \land learned(l_i,learned_i) \implies \exists \sigma_1,\sigma_2 \in \mathcal{P}, learned_i \thicksim learned_j \bullet \sigma_1 \lor learned_j \thicksim learned_i \bullet \sigma_2$}\par
\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} By 1.}\par
\parbox{\linewidth}{\strut3. Q.E.D.} \par

\subsubsection{Non-Triviality}
\begin{theorem}
If all proposers are correct, $learned_l$ can only contain proposed commands. \label{N-T1} \par
\end{theorem} 
\textbf{Proof:} \par
\parbox{\linewidth}{\strut1. At any given instant, $\forall l_i \in \mathcal{L}, \forall s \in \mathcal{P}, learned(l_i,s) \implies \forall x \in \mathcal{P}, \exists \sigma \in \mathcal{P},  maj\_accepted(s) \lor (min\_accepted(s) \land  (s \thicksim x \bullet \sigma \lor x \thicksim s \bullet \sigma))$ }\par
\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} By Algorithm \ref{BFT-Acc} lines \{28-43\} and Algorithm \ref{BFT-Learn} lines \{1-4\}, if a correct learner learned a sequence $s$ at any given instant then either $N-f$ or $f+1$ (if $s$ is universally commutative) acceptors must have executed phase $2b$ for $s$.}\par
\parbox{\linewidth}{\strut2. At any given instant, $\forall s \in \mathcal{P}, maj\_accepted(s) \lor min\_accepted(s) \implies proposed(s)$ }\par
\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} By Algorithm \ref{BFT-Acc} lines \{15-19, 28-43\}, for either $N-f$ or $f+1$ acceptors to accept a proposal it must have been proposed by a proposer.}\par
\parbox{\linewidth}{\strut3. At any given instant, $\forall s \in \mathcal{P}, learned(l_i,s) \implies proposed(s),\forall l_i \in \mathcal{L}$}\par
\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} By 1 and 2.}\par
\parbox{\linewidth}{\strut4. Q.E.D.}\par

\subsubsection{Stability}
\begin{theorem}
If $learned_l = s$ then, at all later times, $s \sqsubseteq learned_l$, for any sequence $s$ and correct learner $l$ \par \label{S-T1}
\end{theorem} 
\textbf{Proof:} By Algorithm \ref{BFT-Learn} lines \{1-4\}, a correct learner can only append new commands to its $learned$ command sequence.

\subsubsection{Liveness}
\begin{theorem}
For any proposal $s$ and correct learner $l$, eventually $learned_l$ contains $s$ \label{L-T1} \par
\end{theorem} 
\parbox{\linewidth}{\textbf{Proof:}} \par
\parbox{\linewidth}{\strut1. $\forall\ l_i \in \mathcal{L},\forall s,x \in \mathcal{P}, \exists \sigma \in \mathcal{P}, maj\_accepted(s) \lor (min\_accepted(s) \land  (s \thicksim x \bullet \sigma \lor x \thicksim s \bullet \sigma))\overset{e}{\implies} learned(l_i,s)$}\par
\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} By Algorithm \ref{BFT-Acc} lines \{28-43\} and Algorithm \ref{BFT-Learn} lines \{1-4\}, when either $N-f$ or $f+1$ (if $s$ is universally commutative) acceptors accepts a sequence $s$ (or some equivalent sequence), eventually $s$ will be learned by any correct learner.}\par
\parbox{\linewidth}{\strut2. $\forall s \in \mathcal{P}, proposed(s) \overset{e}{\implies} \forall x \in \mathcal{P}, \exists \sigma \in \mathcal{P}, maj\_accepted(s) \lor (min\_accepted(s) \land  (s \thicksim x \bullet \sigma \lor x \thicksim s \bullet \sigma))$} \par
\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} A proposed sequence is either conflict-free when its incorporated into every acceptor's current sequence or it creates conflicting sequences at different acceptors. In the first case, it's accepted by a quorum (Algorithm \ref{BFT-Acc} lines \{38-43\}) and, in the second case, it's sent in phase $1b$ messages to the in leader in the next ballot (Algorithm \ref{BFT-Acc} lines \{20-26\}) and incorporated in the next proposal (Algorithm \ref{BFT-Lead} lines \{13-18,20-32\}).} \par
\parbox{\linewidth}{\strut3. $\forall l_i \in \mathcal{L}, \forall s \in \mathcal{P}, proposed(s) \overset{e}{\implies} learned(l_i,s)$} \par
\indent\indent\parbox{\linewidth}{\strut\textbf{Proof:} By 1 and 2.} \par
\parbox{\linewidth}{\strut4. Q.E.D.}